\chapter{Estado del Arte}\label{chapter:state-of-the-art}

\todo[inline]{comienza demasiado duro. falta llegar primero a qué son los sesgos y que tiene que ver eso con ML. o sea, faltan uno o dos parráfos antes de caer que pueden venir de diferentes fuentes. En un paper no lo harías, pero es que el capítulo del estado del arte tiene comenzar lo más arriba posible.}
Los métodos de aprendizaje automático se han vuelto cada vez mas populares en los ultimos años, tanto en la diversidad como en la importancia de sus aplicaciones~\parencite{}
% FROM SURVEY
% Machine Learning (ML) has been increasingly popular in recent years, both in the diversity and importance of applications [1]. ML is used in a variety of critical decision- making applications including justice risk assessments [2], [3] and job recommendations [4].
%While ML systems have the advantage to relieve humans from tedious tasks and are able to perform complex calcu- lations at a higher speed [5], they are only as good as the data on which they are trained [6]. ML algorithms, which are never designed to intentionally incorporate bias, run the risk of replicating or even amplifying bias present in real-world data [6], [7], [8]. This may cause unfair treatment in which some individuals or groups of people are privileged (i.e., receive a favourable treatment) and others are unprivileged (i.e., receive an unfavourable treatment). In this context, a fair treatment of individuals constitutes that decisions are made independent of sensitive attributes such as gender or race, such that individuals are treated based on merit [9], [10], [11]. For example, one can aim for an equal probability of population groups to receive a positive treatment, or an equal treatment of individuals that only differ in sensitive attributes.

Los sesgos que muestran los algoritmos de aprendizaje automático provienen de diversas fuentes.
Una de las más comunes son las colecciones de datos, de las cuales los modelos de aprendizaje automático implícitamente aprenden a expresar tales sesgos.
Los sesgos contenidos en las colecciones de datos pueden ser a veces el resultado de errores durante su construcción, pero es usual que tengan su origen en procesos históricos.
Cuando estos sesgos son utilizados para realizar una predicción, puede dar lugar a decisiones injustas acerca de los individuos.

Los sesgos pueden incluso provenir de fuentes mas difíciles de detectar para el usuario.
Por ejemplo, la popularización de representaciones semánticas autogeneradas, tales como \emph{word embeddings} pueden contribuir a la propagación de sesgos contenidos en datos históricos~\parencite{bolukbasi2016man}.
Luego, incluso cuando se trabaja con una colección de datos que no contiene explícitamente nada relacionado con género o raza, por ejemplo, al utilizar \emph{word embeddings} clásicos para procesar datos en forma de texto, pueden obtenerse decisiones sesgadas a causa de sesgos que, como se ha probado, contienen los \emph{word embeddings}.

Es posible que los modelos de aprendizaje automático produzcan decisiones injustas incluso asumiendo que sus datos de entrenamiento no tenían sesgos.
Es decir, el modelo de aprendizaje automático ha construido una hipótesis que no generaliza completamente los datos no vistos durante el entrenamiento o incluso los propios ejemplos entrenantes.
Luego, cuantificar los sesgos que un modelo de aprendizaje automático tiene respecto a un conjunto de datos es una tarea usual.
Se hace imprescindible proveer una definición que permita capturar el concepto de equidad y analizar los sesgos que presenta un modelo de forma objetiva.

\section{Definiciones de Equidad}

Múltiples definiciones han sido propuestas para capturar diferentes criterios de equidad.
No existe en estos momentos una única definición ampliamente aceptada de lo que es \textit{equidad}, sino que diferentes definiciones codifican diferentes características que se muestran útiles en diferentes contextos.
Incluso, algunas de las definiciones más comunes presentan conflictos entre si.
A continuación se presentan algunas de las definiciones mas utilizadas. 

% Our system is designed to work with any selection of one or more fairness definitions.
% The only constraint tied to the fairness definition is that it should only depend on: the protected attribute, the predicted class, and the gold class, of each individual in the collection, since those three are the parameters used in the standard fairness definitions.
% These definitions are transformed into fairness metrics either by computing the difference between the highest and lowest evaluations across protected groups or by computing the ratio between those two evaluations.

%Sea $Y$ la clasificación (binaria) correcta, $S$ el atributo protegido, y $Y^p$ la clasificación obtenida del modelo.

 \begin{itemize}
     \item \textbf{Statistical Parity (SP)}: Un clasificador binario $\hat{Y}$ satisface \emph{statistical parity} si $P(\hat{Y}=1|P=1) = P(\hat{Y}=1|P=0)$.
     Esto es, la probabilidad de un resultados positivo debería ser la misma sin importar si el individuo pertenece a un grupo protegido~\parencite{verma2018fairness}.
     \item \textbf{Equal Opportunity (EO)}: Un clasificador binario $\hat{Y}$ satisface \emph{equal opportunity} con respecto a $P$ y $Y$ si $P(\hat{Y}=1|Y=1,P=1) = P(\hat{Y}=1|Y=1,P=0)$.
     Esto significa que la probabilidad de que a una persona en la clase positiva le sea asignada un resultado positivo debería ser igual para miembros tanto de grupos protegidos como no protegidos~\parencite{verma2018fairness}.
     \item \textbf{Equalized Odds (EOdd)}: Un clasificador binario $\hat{Y}$ satisface \emph{equalized odds} con respecto al atributo protegido $P$ y predicción $Y$, si $P(\hat{Y}=1|Y=y,P=1) = P(\hat{Y}=1|Y=y,P=0)$, es decir, $\hat{Y}$ y $P$ son independientemente condicionales a $Y$.
     Esto significa que la probabilidad de que a una persona en la clase positiva le sea asignada correctamente una predicción positiva y la probabilidad de que a una persona en la clase negativa le sea incorrectamente asignada una predicción positiva debería ser la misma para miembros de grupos protegidos y no protegidos~\parencite{verma2018fairness}.
 \end{itemize}

Las concesiones inherentes a utilizar cada noción de equidad han sido estudiados extensamente \parencite{dwork2012fairness, friedler2016possibility, kleinberg2018inherent}.
Escoger la definición correcta para un problema determinado es difícil, y en la práctica no puede ser delegado a un agente automático.
En su lugar, una decisión humana es preferida para asegurar una decisión informada.

Es posible transformar las definiciones de equidad presentadas anteriormente para obtener métricas que de cuantifiquen el sesgo de un clasificador.
Por ejemplo, \emph{Differential Statistical Parity} (\texttt{DSP}) puede ser obtenida utilizando la definición de \emph{Statistical Parity} para obtener una medida de la diferencia entre la cantidad de resultados positivos entre los diferentes grupos protegidos.
Luego, estas métricas pueden ser utilizadas como funciones de perdida a emplear en algoritmos de optimización que permitirán mitigar los sesgos de los modelos.

\section{Mitigación de sesgos}\label{section:mitigation}

%% From FBO

Las técnicas de mitigación de sesgos pueden ser divididas fundamentalmente en técnicas de pre-procesamiento, post-procesamiento y técnicas durante el procesamiento. Adicionalmente un conjunto de técnicas llamadas meta-algoritmos han surgido recientemente, presentando muy buenos resultados.

Las técnicas de pre-procesamiento logran equidad modificando la representación de los datos, es decir, pre-procesando los datos y luego adoptando una solución de aprendizaje automático estándar \parencite{nips2017preproc, Kamiran2011DataPT, zemel2013learning}.
Un ejemplo de esto es: aprender una representación a partir de resolver un problema de optimización con dos objetivos, codificar la información preservando la mayor cantidad de información posible y ofuscar al mismo tiempo la pertenencia al conjunto de atributos protegidos \parencite{zemel2013learning}.
Una ventaja de los métodos de pre-procesamiento es que son agnósticos al modelo.
Sin embargo, sus hiperparámetros, así como los del modelos de aprendizaje automático seleccionado, todavía necesitan ser ajustados para mejor rendimiento.

Los métodos aplicados durante el procesamiento aseguran que se cumplan ciertas restricciones de equidad durante el entrenamiento~\parencite{donini2018empirical, zafar2017fairness, zafar2019fairness}, sin embargo, esto los hace aplicable solo a una cierta clase de modelos.
Por ejemplo, el algoritmo propuesto por \emph{Donini et al.}~\parencite{donini2018empirical} solo puede ser aplicado a \emph{kernel machines} (tales como \emph{maquinas de soporte vectorial}), y con la limitación adicional de poder trabajar exclusivamente con una única definición de equidad (\emph{Equal Opportunity}).
Aunque las técnicas de mitigación durante el procesamiento pueden brindar muy buenos resultados para la clase del modelo que están diseñados, frecuentemente son difíciles, o a veces imposible, de extender para nuevas clases de modelos.
Estos métodos también pueden introducir nuevos hiperparámetros que podrían requerir conocimiento específicos del dominio y experimentación.

Las técnicas de post-procesamiento operan ajustando el umbral de decisión de modelos pre-entrenados para eventualmente lograr resultados más justos respecto a una métrica de equidad dada.
El principal problema es que post-procesar el umbral de decisión es inherentemente subóptimo y puede llevar a peores balances de eficacia y equidad.
Adicionalmente, estas técnicas no son utilizables si la información sensible no esta disponible en el momento de realizar las predicciones
El conocimiento de información sensible de los individuos reales por parte del sistema en el momento de realizar las predicciones puede llevar a problemas legales~\parencite{MacCarthy2018StandardsOF}.

Finalmente, resultan relevantes los llamados meta-algoritmos, una clase de métodos recientemente propuesta para tareas de clasificación justa.
Estos reducen la tarea de clasificación justa a una secuencia de problemas de clasificación con costo asociado a sus errores de predicción \parencite{agarwal2018reductions, agarwal2019fair, kearns2018preventing}.
Las soluciones a estos problemas suelen producir un clasificador \emph{randomizado}. Contrario a los métodos que funcionan durante el procesamiento, los meta-algoritmos no dependen del tipo de los modelos que se utilizan en el clasificador, sino en la capacidad de los mismos para ser reentrenados repetidamente.
En el contexto de algoritmos de Minimización del Riesgo Empírico (\emph{ERM} por sus siglas en inglés), estos métodos son agnósticos al modelo de aprendizaje automático, pero aun necesitan implementaciones específicas basadas en la definición de equidad seleccionada y necesitan producir un ensemble de modelos. Limitaciones similares caracterizan un número de enfoques que utilizan optimización \parencite{chiappa2018causal,Dimitrakakis_Liu_Parkes_Radanovic_2019} o inferencia bayesiana \parencite{kearns2018preventing,thomas2019preventing}, sus implementaciones tienen que estar diseñadas específicamente para ciertas definiciones de equidad.

Varios algoritmos han sido propuestos en la literatura, que se acogen a uno de los enfoques anteriormente descritos o combinan varios de ellos.
A continuación se exploran algunos de estos métodos que resultan sumamente relevantes para el presente trabajo.

\begin{description}

\item[\emph{Fair Bayesian Optimization}~\parencite{perrone2021fbo}]
Motivado por la versatilidad del ajuste de hiperparámetros, propone un enfoque basado en \emph{Optimizacion Bayesiana} (\emph{BO}) general restringida.
La \emph{Optimizacion Bayesiana} es una metodología bien establecida para optimizar funciones de caja negra costosas de evaluar.
La técnica propuesta por \emph{FBO} optimiza los hiperparámetros de una función de caja negra de forma agnóstica al modelo, mientras se satisfacen restricciones de equidad.
\emph{FBO} se basa fundamentalmente en la hipótesis de que ajustar los hiperparámetros de un modelo es suficiente para encontrar un balance adecuado entre eficacia y equidad.

\item[\emph{SMOTE} \parencite{chawla2002smote}]
Propone un método de preprocesamiento para colecciones de datos desbalanceadas.
El enfoque de este método se basa fundamentalmente en el sobre-muestreo de los datos pertenecientes a las clases menos representadas en la colección.
Utiliza un algoritmo que genera nuevos ejemplos a partir de modificaciones en los ejemplos pertenecientes a dicha clase existentes en los datos.
En muchas ocasiones los sesgos en los modelos vienen dado precisamente por un desbalance en la cantidad de individuos de los grupos protegidos que pertenecen a una clase determinada respecto a otras, por lo que técnicas como \emph{SMOTE} permiten mitigar este problema.

\item[\emph{Fair Empirical Risk Minimization}~(\emph{FERM})~\parencite{FERM}.]
Introduce una generalización de las diferentes nociones de equidad, las cuales restringen el \emph{riesgo condicional} de un clasificador de acuerdo a una función de perdida predeterminada y un parámetro de aproximación.
Este intenta resolver el problema de minimizar el riesgo esperado para un conjunto predeterminado de funciones, utilizando una modificación de \emph{Empirical Risk Minimization} a la cual se refieren como \emph{Fair Empirical Risk Minimization}.
Además, se proponen ejemplos concretos de algoritmos como \emph{Máquinas de Soporte Vectorial} mejorados para satisfacer estas restricciones de equidad.
Finalmente se muestra como para el caso lineal de la restricción de equidad modificada, este enfoque se reduce a un paso de preprocesamiento sobre la colección de datos. %, haciendo cumplir las restricciones de equidad a cualquier modelo linear ajustado sobre los mismos.

\item[\emph{Zafar et al.}~\parencite{zafar2017fairness}.] El trabajo realizado por  los autores introduce una métrica para la equidad del umbral de decisión, la \emph{covarianza del umbral de decisión}.
Utilizando esta métrica como base, se definen dos problemas a resolver, la optimización de la equidad con restricciones sobre la precisión, y la optimización de la precisión con restricciones sobre la equidad.
Los autores realizan modificaciones a \emph{Regresión Logística} y \emph{Maquinas de Soporte Vectorial} para utilizar estas restricciones y resolver estos problemas propuestos.

\item[\emph{Mitigación de Sesgos mediante Aprendizaje Adversarial}~\parencite{zhang2018mitigating}.] Replantea el problema de mitigación de sesgos como un problema de aprendizaje profundo adversarial~\parencite{goodfellow2014adversarial}.
Esto significa que la tarea se reduce a encontrar un modelo predictor que resuelva el problema de clasificación a la vez que intenta que un adversario no pueda inferir el valor de los atributos protegidos a partir de la predicción.

\end{description}

\section{Métodos de ensemble}\label{section:ensembles}

Los métodos de ensemble están diseñados para intentar resolver el problema de bajo~\emph{bias}~/~alta~varianza que muestran la mayoría de los modelos de aprendizaje automático, haciéndolos apropiados para generar modelos de clasificación más robustos \parencite{polikar2006ensemble}.
Un modelo de ensemble está diseñado a partir de muchos modelos con bajo~\emph{bias} cuyas predicciones son combinadas para producir una predicción final.
Se asume fundamentalmente que la combinación de varias predicciones de bajo nivel producirá una salida con baja varianza mientras mantiene un bajo~\emph{bias}.
Tener un conjunto diverso de modelos de bajo nivel es una característica fundamental para lograr esto \parencite{polikar2006ensemble}.
Sin embargo, esto requiere que clasificadores individuales cometan errores en diferentes instancias.
La intuición es que si cada clasificador comete errores diferentes, entonces una combinación estratégica de estos clasificadores puede reducir el error total. Luego, es necesario lograr que cada clasificador sea lo más único posible, particularmente con respecto a ejemplos erróneamente clasificados.

La naturaleza de múltiples hipótesis de los métodos de ensemble asegura que, si son ajustados lo suficiente, tendrán resultados mejores que cualquiera de los modelos individuales en el caso general. Esto les permite también estimar el grado de confianza o calidad de las predicciones que producen. Las técnicas clásicas de ensemble incluyen \emph{voting} y \textit{weighted voting}~\parencite{dietterich2000ensemble}, \emph{boosting}~\parencite{schapire1990strength}, y \emph{bagging}~\parencite{breiman1996bagging}.

En un problema de clasificación, \emph{voting} produce como salida la etiqueta que tiene la mayoría de los votos, tratando cada predicción de los modelos ensamblados como un voto.
\emph{Weighted-voting} funciona de forma similar a \emph{voting}, pero a cada modelo del ensemble le es asignado un \emph{peso} que indica la importancia de su voto.
\emph{Boosting} ejecuta un proceso iterativo donde los modelos son entrenados secuencialmente, cada uno tratando de mejorar su rendimiento en los ejemplos entrenantes donde los modelos anteriores tuvieron peor rendimiento.
Durante este proceso, a cada submodelo le es también asignado un peso que marca la importancia de su predicción.
\textit{Bagging} entrena cada submodelo en una selección diferente (con reemplazo) de los ejemplos entrenantes originales.
%De esta forma, un modelo con una alta varianza debería producir modelos entrenados con alta diversidad.
Alternativamente, \textit{feature bagging} funciona de forma similar, seleccionando un subconjunto de características en lugar de los ejemplos entrenantes, causando que características correlacionados sean analizados de forma separada en algunos submodelos.

Las capacidad de los métodos de ensemble para construir modelos más robustos los ha hecho apropiados para múltiples aplicaciones.
El dominio de la salud es uno de los ejemplos donde estos métodos han sido aplicados con gran éxito.
Por ejemplo, una aplicación híbrida de métodos de ensemble con redes neuronales en un entorno de aprendizaje por reforzamiento ha sido presentada para al predicción de infección de COVID-19 con gran precisión~\parencite{JIN2022105560}.
De forma similar, un método de toma de decisión multicriterio basado en ensembles ha sido propuesto para la detección de COVID-19 a partir del sonido de la tos en pacientes \parencite{CHOWDHURY2022105405}.
Existen ejemplos también no relacionados a la medicina, por ejemplo, \emph{Livieris et al.}~\parencite{livieris2020ensemble} emplea estrategias de ensemble como \textit{ensemble-averaging}, \textit{bagging} y \textit{stacking} con metodologías avanzadas de aprendizaje profundo para predecir los precios, a nivel de hora, de criptomonedas como \textit{Ethereum}, \textit{Bitcoin} y \textit{Ripple}.

Una simple pero poderosa técnica en el contexto de los métodos de ensemble es la llamada \textit{snapshot ensemble} \parencite{huang17snapshot}. Esta técnica genera múltiples clasificadores base, entrenando una sola red neuronal mientras la hace converger de forma rápida y repetida a múltiples óptimos locales y salvando en cada uno de dichos puntos los parámetros del modelo. Todas las redes neuronales son luego ensambladas para producir el clasificador final. Estos \textit{snapshot ensemble} son mas robustos y precisos que las redes individuales dada su naturaleza de ensemble, sin ningún costo adicional de entrenamiento.

Como se puede observar, los métodos de ensemble son muy poderosos.
Estos son capaces de construir sistemas que a partir de las predicciones de un conjunto de modelos (quizás no lo suficientemente expresivos) generalizan bien y obtienen resultados satisfactorios.
Sin embargo, es necesario para la construcción de estos ensembles se debe partir de un conjunto de modelos base previamente obtenidos, que cumplan determinadas características.
Luego, resulta sumamente interesante explorar enfoques que permitan obtener estos modelos base de forma automática para un problema determinado, de forma tal que no sea necesario manualmente tomar decisiones acerca de el tipo de modelos a utilizar, lo hiperparámetros de los mismos, etc. 

\section{Métodos de AutoML}\label{section:automl}

\emph{AutoML} (del inglés \textit{Automated Machine Learning}) es el proceso de automatizar la solución de problemas del mundo real a través de técnicas de aprendizaje automático.
El proceso intenta eliminar la necesidad de humanos expertos en aprendizaje automático para seleccionar apropiadamente las características, flujos, paradigmas, algoritmos y sus hiperparámetros para resolver un problema \parencite{Dimitrakakis_Liu_Parkes_Radanovic_2019}.
Las principales ventajas de las tecnologías de \emph{AutoML} incluyen:
(1) reducir el tiempo empleado en resolver problemas bien estudiados; y,
(2) eliminar la necesidad de conocimiento experto.
Adicionalmente, estas tecnologías tienden a generar soluciones más simples que a menudo tienen mejor desempeño que soluciones diseñadas por humanos.

Múltiples tecnologías han sido propuestas para resolver el problema de \emph{AutoML}. \emph{AutoWeka}~\parencite{autoweka} fue una de las primeras soluciones presentadas.
Esta solución está basada en el software \emph{Weka}~\parencite{weka}, un software construido a partir de varias herramientas de visualización y algoritmos para análisis de datos y modelación predictiva. \emph{AutoWeka} resuelve el problema de \emph{AutoML} como un problema \emph{CASH} según definido a continuación.

\begin{definition}
\label{definition:cash}
    Sea $A = \{A^{(1)}, \dots, A^{(R)}\}$ un conjunto de algoritmos, y sea $\Lambda^{(j)}$ el dominio de los hiperparámetros del algoritmo $A^{(j)}$.
    Sea, $D = \{(x_1, y_1), \dots, (x_n, y_n)\}$ el conjunto de entrenamiento, el cual es dividido en $K$ \emph{cross-validation folds} de la forma $\{D_{valid}^{(1)}, \dots, D_{valid}^{(K)}\}$ y $\{D_{train}^{(1)}, \dots, D_{train}^{(K)}\}$ tal que $D_{train}^{(i)} = D \setminus D_{valid}^{(i)}$ para todo $i = 1, \dots, K$. Finalmente, denótese $L(A_{\lambda}^{(j)}, D_{train}^{(i)},D_{valid}^{(i)})$ la perdida del algoritmo $A^{(j)}$ en $D_{valid}^{(i)}$ con hiperparámetros $\lambda$.
    Entonces, el problema de \textit{Selección de Algoritmo y Optimización de Hiperparámetros Combinado (CASH)} es encontrar la configuración conjunta de algoritmo e hiperparámetros que minimiza la perdida:

    \begin{equation}
        A^{\star}, \lambda_{\star} \in argmin_{A^{(j)}, \lambda \in \Lambda^(j)} \frac{1}{K} \sum_{i=1}^K L(A_{\lambda}^{(j)}, D_{train}^{(i)},D_{valid}^{(i)})
    \end{equation}
\end{definition}

Otros sistemas populares de \emph{AutoML} son \emph{AutoSklearn}~\parencite{feurer2015efficient} y \emph{AutoKeras}~\parencite{autoKeras}.
Estos sistemas están basados en las bibliotecas de aprendizaje automático \emph{ScikitLearn}~\parencite{pedregosa2011scikit} y \textit{Keras}~\parencite{chollet2015keras}, respectivamente.
Ambos sistemas proveen una interfaz para encontrar la mejor arquitectura de aprendizaje automático para resolver un problema.
Una diferencia fundamental entre ellos es la forma en que sus espacios de búsqueda son definidos.
Mientras AutoSkLearn explora espacio de búsqueda condicional, es decir, un espacio con algunos hiperparámetros condicionados a otros, AutoKeras realiza una \emph{Búsqueda de Arquitectura Neuronal (NAS)}~\parencite{NAS}, la cual implica explorar espacios jerárquicos de complejidad arbitraria.

AutoGOAL \parencite{autogoal, estevez2020general} es una de las más recientes contribuciones al campo del AutoML. AutoGOAL es un sistema que utiliza técnicas heterogéneas para resolver el problema CASH.
AutoGOAL se refiere a los modelos que construye como flujos, dado que cada uno de ellos esta formado por algoritmos interconectados.
La esencia de AutoGOAL radica en su espacio personalizable de flujos y su conjunto de algoritmos de búsqueda, que son usados para encontrar la mejor configuración para resolver un problema.
Cada flujo está definido como un conjunto de algoritmos interconectados que traducen una entrada predefinida a su salida correspondiente.
El espacio de flujos comprende no solo el conjunto de algoritmos, sino también sus hiperparámetros.

Múltiples fuentes de algoritmos están incluidos en el espacio de AutoGOAL, tales como \textit{ScikitLearn}~\parencite{pedregosa2011scikit}, \textit{NLTK}~\parencite{nltk}, \textit{Keras}~\parencite{chollet2015keras}, y \textit{Pytorch}~\parencite{paszke2019pytorch}.
Sin embargo, AutoGOAL carece de la habilidad de combinar múltiples flujos de extremo a extremo para generar una solución.
Esta limitación puede ser superada con la utilización de ensembles.

El proceso fundamental de optimización utilizado en AutoGOAL en estos momentos esta basado en una técnica de optimización con Evolución Gramatical para gramáticas probabilistas libres del contexto \parencite{megane2021probabilistic}.
El proceso consiste de un ciclo de generación y evaluación, utilizando una gramática $G$ apropiada para describir el problema de aprendizaje de maquina que se intenta resolver.
En cada iteración un conjunto de $N$ flujos es generado a partir de tomar muestras de la gramática $G$ de acuerdo a las probabilidades $\theta$ asignadas a cada producción.
Estas probabilidades son inicializadas con una distribución uniforme $\theta_0$ para todas las producciones.
Cada flujo es evaluado (lo cual consiste simplemente en entrenamiento y ejecución), y los de mejor desempeño son utilizados para modificar $\theta$, con el objetivo de maximizar la probabilidad de que estos sean generados. Este proceso se ilustra en el algoritmo 

\begin{algorithm}[htb!]
    \caption{PGE\label{algorithm:pge}}

    \CommentSty{Input:}\\
    \quad $N$ $\leftarrow$ tamaño de la población \\
    \quad $n$ $\leftarrow$ numero de individuos seleccionados en cada iteración \\
    \quad $\alpha$ $\leftarrow$ factor de aprendizaje \\
    \quad $G$ $\leftarrow$ gramática que describe los flujos de aprendizaje de maquina a explorar \\
    \quad $\theta_0$ $\leftarrow$ probabilidades iniciales (uniforme) \\
    \quad $f$ $\leftarrow$ función de \emph{fitness} (entrenamiento y evaluación de flujos) \\
    
    \vspace{10pt}

    \SetKwData{best}{\textit{best}}

    $\best \leftarrow none$

    \For{cada iteración $i$}{
        $P_i$ $\leftarrow$ generar población utilizando gramática $G$, con probabilidades $\theta_{i-1}$ \\
        \For{cada solución $S \in P_i$}{
            $f(S)$ $\leftarrow$ calcular \emph{fitness} de $S$ (evaluar el flujo) \\
        }

        $\best \leftarrow argmax_{S \in P \cup \{\best\}} \{f(S)\}$ \\
        $P_{i}^{*}$ $\leftarrow$ seleccionar los $n$ mejores individuos de $P_i$ \\
        $\theta_i^{*}$ $\leftarrow$ calcular la distribución marginal de $P^{*}$ \\
        $\theta_i \leftarrow \alpha \theta_i^{*} + (1-\alpha)\theta_{i-1}$ \\
    }
    \Return{\best} \\
\end{algorithm}

A pesar de la gran variedad de algoritmos que AutoGOAL tiene a su disposición y los satisfactorios resultados que obtiene para una gran variedad de problemas, es una limitación significativa el hecho de que solo es posible optimizar una función objetivo.
La capacidad de AutoGOAL para encontrar modelos que optimicen múltiples funciones objetivos simultáneamente posibilitaría la solución de un amplio espectro de problemas que son inherentemente multi-objetivo.


\section{Optimización Multiobjetivo}\label{section:multiobjective}

Los métodos de optimización multiobjetivo son aquellos que exploran el espacio de búsqueda optimizando simultáneamente diferentes funciones.

\begin{definition}[Optimización Multiobjetivo]
\label{definition:multiobjective}

    Dadas $m$ funciones objetivo $f_1: X \rightarrow \mathbf{R}, \dots, f_m: X \rightarrow \mathbf{R}$ las cuales traducen el espacio $X$ en $\mathbf{R}$, un problema de optimización multiobjetivo esta dado es expresado de la siguiente forma:

    \begin{equation}
        minimizar f_1(x), \dots, minimizar f_m(x), x \in X
    \end{equation}
\end{definition}

Al trabajar con múltiples funciones objetivos es necesario encontrar formas de comparar dos soluciones en el espacio de soluciones factibles.
El concepto de \textit{Pareto dominación} juega un papel fundamental en el ámbito de la optimización multiobjetivo, dado que permite comparar objetivamente dos vectores de forma precisa, sin requerir información adicional de preferencia.

\begin{definition}[Pareto Dominación]
\label{definition:pareto-dominance}

    Dados dos vectores en el espacio objetivo, dígase $y^{(1)}, y^{(2)} \in \mathbf{R}^m$ , entonces el punto $y^{(1)}$ se dice que \textbf{\textit{pareto-domina}} a $y^{(2)}$ si y solo si:

    \begin{equation}
        \forall_{i\in\{1,\dots,m\}}: y_i^{(1)} \leq y_i^{(2)} y \exists_{j\in\{1,\dots,m\}}: y_j^{(1)} \le y_j^{(2)}
    \end{equation}
\end{definition}

\begin{definition}[Frente pareto]
\label{definition:pareto-front}
    Todos aquellos vectores $x$ del espacio objetivo tal que no exista otro vector $z$ en el espacio objetivo que \textbf{pareto-domine} a $x$.
\end{definition}

Tradicionalmente los problemas de optimización multiobjetivo han sido atacados utilizando técnicas de escalarización~\parencite{miettinen2012nonlinear}.
Estas técnicas consisten en de alguna forma combinar todas las funciones objetivos en una sola o reescribirlas como restricciones.
Varias técnicas existen en este contexto. \textit{Linear Weighting} es una de estas, en la cual se construye una nueva función objetivo a partir de la combinación lineal de las funciones objetivo del problema original, esto es $min \sum w_i f_i(x), x \in X$.
Este enfoque tiene un problema fundamental y es que si el \emph{frente pareto} no es convexo, no es posible encontrar soluciones en esta zona, no importa los pesos $w_i$ que se utilicen.
Otra forma de escalarización es \textit{$\epsilon$-constrain}, esta técnica selecciona una función como la \textit{principal} y las demás se establecen como restricciones al conjunto de soluciones factibles, exigiendo que sean menores que un $\epsilon$.
\emph{Random Scalarization} \parencite{paria2020flexible} propone una estrategia basada en escalarizaciones aleatorias de las funciones objetivo.
En lugar de optimizar una única escalarización de las funciones objetivos, este enfoque itera sobre un conjunto de escalarizaciones durante un proceso de \emph{Optimización Bayesiana}.
Finalmente, \emph{ParEGO} \parencite{knowles2006parego} es una extensión de \emph{EGO} \parencite{jones1998ego} para la utilización en escenarios multiobjetivos.
Utiliza un enfoque que combina las diferentes funciones objetivo en una sola a partir de una escalarización utilizando un vector de pesos parametrizado, utilizando diferentes parámetros para dicho vector de pesos el \emph{Frente Pareto} es construído de forma gradual.

Existen métodos numéricos que intentan resolver el problema haciendo cumplir las condiciones de \emph{Karush-Kuhn-Tucker} \parencite{kuhn2014nonlinear}.
La idea va de encontrar al menos una solución del sistema de ecuaciones que se produce al tratar el problema de \textit{KKT}.
Es posible utilizar métodos de continuación y homotopía para obtener todas las soluciones \parencite{hillermeier2001nonlinear, schutze2005continuation}.
Estos métodos requiere que las soluciones satisfagan condiciones de convexidad local y diferenciabilidad.

Los algoritmos genéticos utilizan paradigmas basados en procesos evolutivos naturales, como \textit{selección natural}, \textit{mutación} y \textit{recombinación} para mover una población (conjunto de vectores de decisión) a soluciones óptimas o casi óptimas \parencite{back1996evolutionary}.
Los algoritmos genéticos multiobjetivo generalizan esta idea y son diseñados para en cada iteración acercarse más al frente pareto.
En este contexto destaca \emph{NSGA-II} \parencite{deb2002nsgaii}, el cual se explica en mayor detalle a continuación.

\subsection*{NSGA-II}

\emph{NSGA-II} es un algoritmo sumamente sencillo, pero aun así ha mostrado ser muy efectivo en la resolución de problemas de optimización multiobjetivo.
El algoritmo consiste básicamente de un ciclo generacional que se divide en dos partes.
En la primera parte, la población pasa por un proceso de variación.
En la segunda parte, un proceso de selección toma lugar, el cual resulta en la población de la nueva generación.
Este proceso se repite hasta que se cumple algún criterio de convergencia o se excede una cantidad de computo predefinida.

En la parte de la variación, $\lambda$ nuevos individuos son generados.
Para cada uno de ellos dos padres son seleccionados de la población actual $P_t$.
Para escoger estos, se utiliza una selección de torneo binario, es decir se escogen aleatoriamente dos individuos de la población y se selecciona el mejor de acuerdo a su \emph{orden} en la población.
Los padres son entonces recombinados utilizando un operador de combinación, el individuo resultante es luego mutado utilizando un operador de mutación.
De esta forma es creado un nuevo conjunto $Q_t$ de individuos, los cuales son añadidos junto a la población actual al conjunto de individuos a considerar para la siguiente generación.

La segunda fase, fase de selección, los $\mu$ mejores individuos son seleccionados del conjunto $P_t \cup Q_t$ utilizando un mecanismo de ordenación multiobjetivo, de esta forma la población de la nueva generación $P_{t+1}$ es formada.
El mecanismo de selección de \emph{NSGA-II} es el ingrediente fundamental que lo distingue del resto de los algoritmos genéticos que son utilizados para resolver problemas de optimización de un único objetivo.
Este consiste de dos niveles.
Primero se realiza un \emph{\textbf{non-dominated sorting}}.
Este depende únicamente del \emph{pareto-orden} entre los individuos.
Finalmente los individuos que comparten el mismo \emph{pareto-orden} son ordenados de acuerdo al \emph{\textbf{crowding-distance}}, la cual es una medida de la diversidad.

% TODO: annadir pseudocodigo de todo esto

\subsubsection{Non-dominated sorting}\label{section:ndsorting}

Sea $\text{ND}(P)$ el conjunto de soluciones no dominadas \ref{definition:pareto-dominance} en una población $P$.
\emph{Non-dominated sorting} particiona la población en subconjuntos, basado en la \emph{pareto dominación} \ref{definition:pareto-dominance} como especifica la siguiente recurrencia.

\begin{align}
    R_1 &= \text{ND}(P) \\
    R_{k+1} &= \text{ND}(P \setminus \cup_{i=1}^k R_i) \quad k = 1,2, \dots
\end{align}

Como en cada paso de la recurrencia al menos una solución es eliminada de la población, el número máximo de \emph{capas} es $|P|$.
El orden de una solución esta dado por el subíndice $k$ del $R_k$ en el cual queda dicha solución.

\subsubsection{Crownding distance}\label{section:crowding-distance}

Si más de una solución quedan en el mismo subconjunto de la población $R_k$ luego de realizar la ordenación anterior, se procede a ordenar las soluciones dentro de dichos subconjunto a partir de su \emph{crowding distance}.
Esta es calculada para una solución $x$ como la suma de las contribuciones $c_i$ a la i~-~ésima función objetivo:

\begin{align}
    l_i(x) = \max \{ f_i(y) | y \in R \setminus \{x\} \wedge_i(y) \leq f_i(x) \} \cup \{-\infty\} \\
    u_i(x) = \min \{ f_i(y) | y \in R \setminus \{x\} \wedge f_i(y) \geq f_i(x) \} \cup \{+\infty\} \\
    c_i(x) = u_i - l_i, \quad i = 1, \dots, m \\
    c(x)   = \frac{1}{m} \sum_{i=1}^m c_i(x), x \in R
\end{align}

Intuitivamente mientras mas \textit{espacio} exista alrededor de una solución, mayor sera el \emph{crowding distance} de la misma.
Por tanto, aquellas soluciones con elevado \emph{crowding distance} son preferidas a aquellas con baja distancia, con el propósito de mantener la diversidad en la población.

\section{Discusión}\label{discussion}
% - discusion. Aqui donde se explica como se usa todo lo q acabo de explicar.

El método propuesto en este trabajo explora la utilización de AutoGOAL como vía para obtener un conjunto de modelos \emph{diversos} base que puedan ser posteriormente ensamblados.
El proceso de construir el ensemble a partir de estos modelos base se realiza mediante una modificación del algoritmo de optimización de AutoGOAL, la cual permite explorar el espacio de búsqueda optimizando simultáneamente varias métricas, como por ejemplo la precisión y una o varias métricas de equidad.
Para la modificación de AutoGOAL este trabajo se inspira en los metodos de selección propuestos por \emph{NSGA-II}, estos son, \emph{Non-dominated Sorting} y \emph{Crowding Distance}.
