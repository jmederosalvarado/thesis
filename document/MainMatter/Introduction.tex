\chapter*{Introducción}\label{chapter:introduction}
\addcontentsline{toc}{chapter}{Introducción}

\newcommand{\todocite}[2]{\textbf{todocite[from~textit{#1}~cite~\textit{#2}]}}

% motivación + problemática + objetivos + contribuciones + párrafo con la estructura del proyecto

%(1) que ML está en todos lados

En los últimos años, ha habido un creciente interés en aplicar técnicas de aprendizaje automático para resolver diferentes tipos de tareas.
Análisis de emociones en textos, etiquetado de imágenes y traducción automática son algunos ejmplos de estas tareas~\todocite{jp}{11,26,2,36}.
En general, los problemas de clasificacion son un de los problemas mas comunes para los cuales los algoritmos de aprendizaje automatico tienden a producir buenos resultados.

%(2) que aplicarlo a toma de decisiones de alto riesgo da lugar a el tema de los sesgos

Con el uso cada vez maz de los metodos de aprendizaje autmatico en dominios tales como \emph{prestamos financieros}, \emph{contratacion}, \emph{justicia criminal}, y \emph{admisiones en las universidades}, ha habido una mayor preocupacion por el potencial de estas tecnicas de accidentalmente codificar sesgos sociales y resultar en una discriminacion sistematica~\todocite{fbo}{4-6,8,10}.
Por ejemplo un clasificador que solamente es ajustado para maximizar la precision de las predicciones puede injustamente predecir un alto riesgo en el credito para algunos subgrupos de la poblacion aplicando a un prestamo.


%(3) que si muchos approach existentes para mitigar son de optimización para alcanzar un trade off

Cuantificar y mitigar los sesgos durante las diferentes etapas del ciclo de vida de los modelos de aprendizaje automatico ha sido objeto de estudio de numerosas investigaciones~\todocite{fbo}{5}
Especificamente, un numero de metodos han sido propuestos recientemente para incrementar la equidad en los resultados producidos por estos modelos.
La clave del diseño detras de todos estas métodos es maximizar la precisión de las predicciones, sujeto a restricciones de equidad sobre los resultados.
Sin embargo, como consecuencia de mantener la tratabilidad computacional de estas tecnicas, estos métodos sufren de una o mas de las siguientes desventajas.
La tecnica de mitigacion es
(i) específica a la clase del modelo utilizado (p.e. solamente modelos lineares),
(ii) limitiada a un conjunto especifico de definiciones de equidad,
(iii) limitado a un unico atributo protegido binario,
(iv) require acceso a informacion sensible en el momento de las predicciones

%Specifically, a number of methods have been proposed in recent
%years to reduce unfairness in the ML model outcomes. The
%key design principle behind all of these fairness interventions is to
%maximize prediction accuracy subject to some constraints on the
%fairness of the outcomes while preserving computational tractability.
%1 However, as an artefact of the need to preserve computational
%tractability, these fairness interventions suffer from one or more
%of the following drawbacks. The fairness intervention is (i) specific
%to the model class (e.g., linear models only), (ii) limited to a
%specific definition(s) of fairness, (iii) limited to a single, binary sensitive
%feature, (iv) requires access to sensitive feature information
%at prediction time, or (v) results in a randomized classifier that may
%generate different prediction for the same input at different times.
%These drawbacks limit the practitioners’ ability to deploy fair ML
%solutions for arbitrary machine learning pipelines corresponding to
%different practical goals and constraints.2 For instance, as a result of
%limitation (i), any ensemble or hybrid learning solutions combining
%different model classes and/or domain knowledge are ruled out. As
%a drawback of limitation (iv), the corresponding fairness intervention
%cannot be used when the sensitive feature information is not
%available at prediction time, while limitation (v) may result in the
%same model accepting and denying the loan to the same applicant
%at different times.


%(4) que si AutoML es bueno para el tema de democratizar una tecnología y que ayuda a crear hipótesis automáticamente
%(5) que si AutoGoal tiene varias ventajas sobre el resto
%(6) finalmente que a partir de combinar ciertas cosas se pueden resolver las limitaciones de otras propuestas actuales

%De ahí caes en objetivos, contribuciones y organización

% importante vender todas las contribuciones explícitamente (eran como 4, y las anotaste)



%In recent years, there has been an increasing interest in applying machine learning techniques to solve several types of
%complex tasks. Text sentiment analysis, image labeling, and machine translation are just a few well-known examples of
%these tasks [1,26,2,36]. In general, classification problems are one of the most common problems for which machine learning
%approaches tend to produce good results. Proof thereof is the fact that machine learning-based systems have been applied
%even in high-risk decision-making contexts, e.g. hiring processes, applications for bank loans, health insurance, criminal
%recidivism, among others [8,17,24,37].

%Recent advances in Automatic Machine Learning (Auto-ML) have enabled the development of libraries and other tools to
%effectively find the best combination of algorithms and hyperparameters to solve a problem [19]. Several technologies have
%been proposed to solve the Auto-ML problem, such as Auto-Weka [35], Auto-sklearn [16], and Auto-Keras [20]. These
%libraries are alternatives for reducing the time spent by researchers in solving well-studied problems. Even if Auto-ML tools
%tend to be more time and resource consuming than standard ML libraries, not having to think about which architecture
%might be the best for solving a problem makes them worth developing. Also, by being applicable to a broad range of problems,
%learning to use these tools may be easier than learning several independent libraries.
%In this context, we find AutoGOAL1 to be a good example of the potential of Auto-ML libraries. AutoGOAL is a novel Auto-ML
%system that uses heterogeneous techniques. In contrast with other existing Auto-ML technologies, AutoGOAL can automatically
%build machine learning pipelines that combine techniques and algorithms from different frameworks, including shallow classifiers,
%natural language processing tools, and neural networks [13,14]. AutoGOAL performs a Probabilistic Grammatical Evolution
%Search to explore the space of available algorithms and their hyperparamenters to build pipelines [15]. At the end of the
%search, the best performing pipeline found according to the input loss function is given as a solution for the problem.
%Even though AutoGOAL is capable of combining algorithms from several different frameworks to build pipelines, it lacks
%the ability to combine multiple end-to-end pipelines to generate a solution. This means that although multiple hypotheses
%are tested while AutoGOAL is searching for the best configuration, the final solution comprises a single end-to-end hypothesis
%and all intermediate pipelines found by AutoGOAL are discarded. However, we consider that these discarded pipelines
%could be a great source of information, especially if the collection of pipelines is intelligently selected to maximize a desired
%criteria.
%One way of combining several hypothesis to produce a more robust solution, i.e. a solution that generalizes better to
%unseen inputs, is through ensemble methods. There are several ensemble methods available in the literature, such as voting
%and weighted-voting [10], boosting [32], and bagging [3]. However, depending on the problem, one ensemble method might
%perform better than the other. This presents the aforementioned challenge of finding the best method to apply to fit a desired
%criteria, a time-consuming task when done manually. This challenge can be overcome by intelligently exploring the space of
%ensemble methods, with their respective hyperparameters, to find the best one to apply.
%We believe that by ensembling the outputs of several pipelines, the single, biased hypothesis that AutoGOAL originally
%generates can be improved, and therefore, a more robust solution can be provided. Also, by having a starting collection of
%pre-trained models, we expect that more complex metrics can be better optimized. Solving problems in two phases to
%enhance performance has been studied in the literature, providing good results [27,22]. Additionally, using ensembles to
%merge multiple snapshots of a single neural network architecture along its optimization path has been proven to be an effective
%technique referred to as snapshot ensembles [18]. By contrast with snapshot ensembles, this paper studies the ensemble
%of several Auto-ML generated models instead of using a single neural network architecture.
%This paper’s objective is to design and validate a system that takes advantage of all the different architectures that are
%generated while solving classification problems with Auto-ML tools, particularly AutoGOAL, to produce more robust classifiers.
%We propose a two-phase optimization system based on Automatic Machine Learning (Auto-ML) for solving classification
%problems. In the first phase, the system follows a probabilistic strategy to find the best combination of algorithms and
%hyperparameters to generate a collection of base models according to certain diversity criteria; and in the second, it follows
%similar Auto-ML strategies to ensemble those models.
%The specific contributions of this research are as follows:
%  We propose a system based on AutoGOAL and ensemble methods to solve arbitrary classification problems. The improvement
%in the generalization capability of the solutions is the main advantage of our proposal, which is available online as a
%python project for the research community.
%  We study how some diversity measures can impact the performance of an ensemble method when used to ensure diversity
%between the collection of base classifiers.
%  We provide the basis for future studies on unfairness and bias mitigation. Since the optimization process is divided into
%two phases, a second loss function can be optimized after the first phase by imposing constraints to limit detriment in
%performance.
%The remainder of the paper is organized as follows. Section 2 gives a brief overview of current research in Auto-ML techniques
%and ensemble methods. Section 3 presents our two-phase optimization system for solving classification problems.
%Section 4 shows the results of evaluating the system. Section 5 discusses the implications of the results we obtained from
%the experiments. Finally, Sections 6 presents the conclusions, along with future lines of work.

En la actualidad los algoritmos de aprendizaje automático están siendo aplicados en disimilies areas de la vida humana. Es comun encontrarlos aplicados en sistemas de recomendacion de compras, aplicaciones de citas, solicitudes de prestamos, contratacion personal y muchas otras areas.  A raiz de ello, ha surgido un creciete interes en estudiar las potencialidades y limitaciones de los modelos de aprendizaje automatico, asi como las posibles implicaciones de confiar ciegamente en sus predicciones.

En particular, su incorporacion a tareas de toma de decisiones de alto riesgo ha dirigido la atencion de muchos investigadores hacia una nueva interrogante: ¿estaran siendo "justos" los algoritmos de aprendizaje automatico al tomar sus decisiones?

En este escenario, ha ganado popularidad el desarrollo de tecnicas para detectar y mitigar los sesgos en colecciones de datos y algoritmos de aprendizaje automatico. Tales herramientas son cruciales para desarrollar sistemas de toma de decisiones mas justos. Los estudios orientados hacia la equidad en algoritmos de aprendizaje automatico se enfocan principalmente en desarrollar tecnicas que consideren tanto la precision como la equidad de los modelos.

\section*{Motivación}

Un modelo de aprendizaje de maquina se entrena con el objetivo de optimizar una unica metrica, en la mayoria de los casos la precision. Esto significa que los modelos aprenden muy bien los patrones que se presentan en los datos de entrenamiento, incluyendo aquellos patrones que representan sesgos y prejuicios que estan desafortunadamente presente en la sociedad y por ende en los datos recopilados, en algunos casos incluso amplifican estos patrones negativos. Son varias la tecnicas que se han explorado para resolver este problema, algunas se enfocan en un preprocesamiento de los datos para eliminar aquellos elementos que puedan inducir un sesgo en el modelo, otras realizan variacinoes en el metodo de entrenamiento con el mismo objetivo. Sin embargo permanece relativamente poco explorado el uso de tecnicas de optimizacion multiobjetivo que permitan al modelo optimizar hasta encontrar un buen balance entre cuan justo es y cuan preciso.

Otra tecnica que ha demostrado ser de gran utilidad en la prevencion de los sesgos en los modelos de aprendizaje de maquina es la construccion de ensamblados de multiples modelos que maximizan la varianza entre si, por lo que se minimiza el sesgo del ensamblado final.

\section*{Problematica}

A pesar de que existe AutoGOAL, una biblioteca de AutoML, que permite obtener modelos para resolver problemas arbitrarios utilizando entre otras tecnicas aprendizaje de maquina. No existe una biblioteca o herramienta que permita resolver de principio a fin un problema de clasificacion utilizando aprendizaje de maquina y donde exita alguna garantia de que el modelo aprendido sea justo.

\section*{Objetivo general}

Proponer una herramienta que permita resolver problemas de clasificacion utilizando aprendizaje de maquina y que permita garantizar que el modelo aprendido sea justo.

\section*{Objetivos especifico}

\begin{itemize}
    \item Encontrar modelos que maximicen la varianza para minimizar el sesgo.
    \item Metodos basados en metaheuristicas para optimizar los modelos utilizando simultaneamente metricas de equidad y precision.
    \item Explorar adicion de optimizacion multiobjetivo a AutoGOAL para que el modelo aprendido sea justo.
    \item Metodos basados en la combinacion de diferentes metricas en una sola, para poder aprovechar los multiples metodos de optimizacion que existen.
\end{itemize}
